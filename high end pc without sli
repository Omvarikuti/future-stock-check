import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow import keras
from keras import layers, mixed_precision
import tensorflow as tf
from tqdm import tqdm
import os

# Use mixed precision for GPU acceleration
mixed_precision.set_global_policy('mixed_float16')

# Create output folder
os.makedirs('intel_lstm_mega_model', exist_ok=True)

# Download stock data
ticker = 'INTC'
data = yf.download(ticker, start='2015-01-01', end='2025-04-18')
close_prices = data['Close'].values.reshape(-1, 1)

# Normalize
scaler = MinMaxScaler()
close_scaled = scaler.fit_transform(close_prices)

# Create sequences
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

seq_length = 100
X, y = create_sequences(close_scaled, seq_length)

# Split data
split = int(0.8 * len(X))
X_train, X_val = X[:split], X[split:]
y_train, y_val = y[:split], y[split:]

# Define attention layer
class AttentionLayer(layers.Layer):
    def __init__(self):
        super(AttentionLayer, self).__init__()

    def call(self, inputs):
        query = key = value = inputs
        scores = tf.matmul(query, key, transpose_b=True)
        weights = tf.nn.softmax(scores, axis=-1)
        return tf.matmul(weights, value)

# Model architecture
def build_strong_model():
    inputs = keras.Input(shape=(seq_length, 1))
    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(inputs)
    x = layers.LayerNormalization()(x)
    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)
    x = AttentionLayer()(x)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dense(512, activation='gelu')(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(256, activation='gelu')(x)
    outputs = layers.Dense(1, dtype='float32')(x)

    model = keras.Model(inputs, outputs)
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])
    return model

model = build_strong_model()
model.summary()

# Training callbacks
callbacks = [
    keras.callbacks.ModelCheckpoint('intel_lstm_mega_model/best_model.h5', save_best_only=True),
    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)
]

# Train model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=100,
    batch_size=2048,
    callbacks=callbacks,
    verbose=1
)

# Predict future
def predict_future(model, last_sequence, steps):
    predictions = []
    current = last_sequence.reshape(-1, 1)
    for _ in range(steps):
        pred = model.predict(current[np.newaxis, :, :], verbose=0)[0, 0]
        predictions.append(pred)
        current = np.append(current[1:], [[pred]], axis=0)
    return np.array(predictions)

future_scaled = predict_future(model, X_val[-1], 50)
future = scaler.inverse_transform(future_scaled.reshape(-1, 1)).flatten()

# Plot predictions
original = scaler.inverse_transform(close_scaled).flatten()
plt.figure(figsize=(12, 6))
plt.plot(range(len(original)), original, label='Original Data')
plt.plot(range(len(original), len(original) + 50), future, label='Future Prediction', linestyle='--')
plt.legend()
plt.title('Intel Stock Price Prediction')
plt.savefig('intel_lstm_mega_model/predictions.png')
plt.show()
